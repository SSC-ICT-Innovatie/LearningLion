{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imports\n",
    "import os\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from loguru import logger\n",
    "# local imports\n",
    "from ingest.ingester import Ingester\n",
    "from query.querier import Querier\n",
    "from summarize.summarizer import Summarizer\n",
    "import settings\n",
    "import utils as ut\n",
    "from query.querier import EnumMode\n",
    "from ingest.ingester import IngestionMode\n",
    "from datetime import datetime\n",
    "import kamervragenEvaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT= \"\"\"\n",
    "### OBJECTIVE ###\n",
    "Je bent een assistent voor de rijksoverheid. Jouw taak is om vragen te beantwoorden in het Nederlands. Zorg ervoor dat je alleen antwoord geeft op basis van de beschikbare context en dat je daar ook naar verwijst in je antwoord.\n",
    "\n",
    "### AUDIENCE ###\n",
    "De doelgroep van jouw antwoorden zijn ambtenaren. Geef alle relevante informatie uit de context, antwoord in het Nederlands leg in maximaal 100 woorden zoveel mogelijk uit.\n",
    "\n",
    "### GUARDRAILS ###\n",
    "Indien de context onvoldoende informatie bevat om de vraag te beantwoorden, verzin dan geen informatie maar geef aan dat er onvoldoende informatie beschikbaar is.\n",
    "\n",
    "### INSTRUCTIONS ###\n",
    "- Beantwoord de vraag altijd in het Nederlands, zelfs als de context in het Engels is gesteld.\n",
    "- Vermijd het herhalen van de vraag in het antwoord en het herhalen van de instructies. Voer de instructies uit en geef een concreet antwoord op de gestelde vraag.\n",
    "- Geef een stapsgewijze redenering bij het beantwoorden van de vraag en refereer naar specifieke zinnen uit de context die hebben bijgedragen aan het antwoord.\n",
    "- Houd je antwoord nauw verbonden met de context en vermijd het toevoegen van informatie die niet expliciet in de context wordt vermeld.\n",
    "\n",
    "- Voor meer informatie over de context, zeg het bestandsnaam die gevonden is in de source_document. Mits deze beschikbaar is.\n",
    "### QUESTION ### \\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Commented the settings that arent used as parameters in the functions\n",
    "\n",
    "# DOC_DIR = \"./docs\"\n",
    "# CHUNK_DIR = \"./chunks\"\n",
    "# VECDB_DIR = \"./vector_stores\"\n",
    "# EVAL_DIR = \"./evaluate\"\n",
    "# EVAL_APP_HEADER = \"Evaluation\"\n",
    "# EVAL_APP_INFO = \"./info/evaluation_explanation.txt\"\n",
    "# EVAL_FILE_NAME = \"eval.json\"\n",
    "# CHAIN_VERBOSITY = False\n",
    "LLM_TYPE = \"local_llm\"\n",
    "LLM_MODEL_TYPE = \"gemma2\"\n",
    "# API_URL = \"http://127.0.0.1:11434\"\n",
    "AZUREOPENAI_API_VERSION = \"2023-08-01-preview\"\n",
    "EMBEDDINGS_PROVIDER = \"local_embeddings\"\n",
    "EMBEDDINGS_MODEL = \"textgain/allnli-GroNLP-bert-base-dutch-cased\"\n",
    "TEXT_SPLITTER_METHOD = \"NLTKTextSplitter\"\n",
    "# CHAIN_NAME = \"conversationalretrievalchain\"\n",
    "# CHAIN_TYPE = \"stuff\"\n",
    "# SEARCH_TYPE = \"similarity\"\n",
    "# SCORE_THRESHOLD = 0.5\n",
    "VECDB_TYPE = \"chromadb\"\n",
    "CHUNK_SIZE = 1024\n",
    "# CHUNK_K = 4\n",
    "CHUNK_OVERLAP = 256\n",
    "# RETRIEVAL_METHOD = \"regular\"\n",
    "\n",
    "\n",
    "folderSelected = \"kamerVragen\"\n",
    "my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected)\n",
    "\n",
    "CONCAT_FILES = True\n",
    "question_sample_CSV = \"question_sample.csv\"\n",
    "VALIDATIONLAPS = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITTING_METHODS = [IngestionMode.question_answer,IngestionMode.token_small,IngestionMode.token_medium,IngestionMode.token_large]\n",
    "CONTEXT_PRESENT= [True, False]\n",
    "EMBEDDINGS_MODELS = [\"GroNLP/bert-base-dutch-cased\",\"textgain/allnli-GroNLP-bert-base-dutch-cased\", \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\"dunzhang/stella_en_400M_v5\", \"actualdata/jina-embeddings-v3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "querier = None\n",
    "ingester = None\n",
    "\n",
    "def init(LLM_TYPE=LLM_TYPE, LLM_MODEL_TYPE=LLM_MODEL_TYPE, EMBEDDINGS_MODEL=EMBEDDINGS_MODEL, EMBEDDINGS_PROVIDER=EMBEDDINGS_PROVIDER, AZUREOPENAI_API_VERSION=AZUREOPENAI_API_VERSION, TEXT_SPLITTER_METHOD=TEXT_SPLITTER_METHOD, CHUNK_SIZE=CHUNK_SIZE, CHUNK_OVERLAP=CHUNK_OVERLAP, VECDB_TYPE=VECDB_TYPE, vectordb_folder= my_vectordb_folder_path_selected, content_folder=my_folder_path_selected):\n",
    "  # Init\n",
    "  querier = Querier(\n",
    "    llm_type=LLM_TYPE, \n",
    "    llm_model_type=LLM_MODEL_TYPE, \n",
    "    embeddings_model=EMBEDDINGS_MODEL, \n",
    "    embeddings_provider=EMBEDDINGS_PROVIDER, \n",
    "    azureopenai_api_version=AZUREOPENAI_API_VERSION\n",
    "    )\n",
    "\n",
    "  ingester = Ingester(\n",
    "    collection_name=folderSelected, \n",
    "    content_folder=content_folder, \n",
    "    vectordb_folder=vectordb_folder,\n",
    "    embeddings_model=EMBEDDINGS_MODEL,\n",
    "    text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    vecdb_type=VECDB_TYPE\n",
    "    )\n",
    "  return [querier,ingester]\n",
    "  \n",
    "# querier,ingester = init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(mode=IngestionMode.question_answer_per_page, forceRebuild=True, addedMetaDataURLCSV=\"docs/metadata.csv\", addContext=True):\n",
    "  ingester.ingest(mode=mode, forceRebuild=forceRebuild, addedMetaDataURLCSV=addedMetaDataURLCSV, addContext=addContext)\n",
    "# ingest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain(vectorDBPATH = my_vectordb_folder_path_selected):\n",
    "  querier.make_chain(folderSelected, vectorDBPATH)\n",
    "# chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_error_log(error, params):\n",
    "  with open(\"error_log.txt\", \"a\") as f:\n",
    "    f.write(f\"{datetime.now()} | {params} - {error}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "querier,ingester = init(EMBEDDINGS_MODEL=EMBEDDINGS_MODEL, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "kamervragenEvaluation.create_evaluation_sample_questions(my_folder_path_selected,ingester=ingester, destinationCSV=question_sample_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place folder contents in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for time in range(VALIDATIONLAPS):\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "      for embeddingModel in EMBEDDINGS_MODELS:\n",
    "        current_item += 1\n",
    "        try:\n",
    "          chunk_size = CHUNK_SIZE\n",
    "          if splittingMethod == IngestionMode.token_small:\n",
    "            chunk_size = 128\n",
    "          elif splittingMethod == IngestionMode.token_medium:\n",
    "            chunk_size = 512\n",
    "          elif splittingMethod == IngestionMode.token_large:\n",
    "            chunk_size = 1024\n",
    "            \n",
    "          # Setup\n",
    "          my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "          querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "          # Ingestion\n",
    "          ingest(mode=splittingMethod, addContext=context, addedMetaDataURLCSV=\"docs/metadata.csv\")\n",
    "          # RAG CHAIN\n",
    "          chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "          \n",
    "          # Evaluation\n",
    "          kamervragenEvaluation.evaluate_with_sample_questions(\n",
    "            question_sample_CSV,querier=querier, \n",
    "            toCSV=True, \n",
    "            ingestionMode=splittingMethod, \n",
    "            addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "            addContext=context,\n",
    "            embeddings_model=embeddingModel,\n",
    "            text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "            embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "            database=VECDB_TYPE,\n",
    "            concatFiles=CONCAT_FILES,\n",
    "            )\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          # Write error to file\n",
    "          write_to_error_log(e, f\"splittingMethod={splittingMethod}, context={context}, embeddingModel={embeddingModel}\")\n",
    "          continue\n",
    "        \n",
    "        \n",
    "        print(f\"done with {current_item} of {total_items}\")\n",
    "  print(f\"Done with iteration {time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LongTimeEmbeddingsModels = [\"BAAI/bge-multilingual-gemma2\", \"Alibaba-NLP/gte-Qwen2-7B-instruct\",\"Alibaba-NLP/gte-multilingual-base\"]\n",
    "\n",
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for time in range(VALIDATIONLAPS):\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "      for embeddingModel in LongTimeEmbeddingsModels:\n",
    "        current_item += 1\n",
    "        try:\n",
    "          chunk_size = CHUNK_SIZE\n",
    "          if splittingMethod == IngestionMode.token_small:\n",
    "            chunk_size = 128\n",
    "          elif splittingMethod == IngestionMode.token_medium:\n",
    "            chunk_size = 512\n",
    "          elif splittingMethod == IngestionMode.token_large:\n",
    "            chunk_size = 1024\n",
    "            \n",
    "          # Setup\n",
    "          my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "          querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "          # Ingestion\n",
    "          ingest(mode=splittingMethod, addContext=context, addedMetaDataURLCSV=\"docs/metadata.csv\")\n",
    "          # RAG CHAIN\n",
    "          chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "          \n",
    "          # Evaluation\n",
    "          kamervragenEvaluation.evaluate_with_sample_questions(\n",
    "            question_sample_CSV,querier=querier, \n",
    "            toCSV=True, \n",
    "            ingestionMode=splittingMethod, \n",
    "            addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "            addContext=context,\n",
    "            embeddings_model=embeddingModel,\n",
    "            text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "            embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "            database=VECDB_TYPE,\n",
    "            concatFiles=CONCAT_FILES,\n",
    "            )\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          # Write error to file\n",
    "          write_to_error_log(e, f\"splittingMethod={splittingMethod}, context={context}, embeddingModel={embeddingModel}\")\n",
    "          continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"done with {current_item} of {total_items}\")\n",
    "  print(f\"Done with iteration {time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re test items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add context to question_sample.csv\n",
    "import pandas as pd\n",
    "\n",
    "from ingest.file_parser import FileParser\n",
    "from ingest.ingest_utils import IngestUtils\n",
    "\n",
    "df = pd.read_csv(question_sample_CSV)\n",
    "file_parser = FileParser()\n",
    "ingestutils = IngestUtils(CHUNK_SIZE, 0, None, TEXT_SPLITTER_METHOD)\n",
    "for index, row in df.iterrows():\n",
    "  if row[\"context\"] != \"\":\n",
    "    continue\n",
    "  # get file\n",
    "  file = row[\"Filename\"]\n",
    "  if file.endswith(\".pdf\"):\n",
    "    file_path = os.path.join(my_folder_path_selected, file)\n",
    "    raw_pages, metadata = file_parser.parse_file(file_path)\n",
    "    documents = ingestutils.clean_text_to_docs(raw_pages, metadata)\n",
    "    introduction = documents[0].page_content.split(\"vraag\")[0]\n",
    "\n",
    "  df.at[index, \"context\"] = introduction\n",
    "  df.to_csv(question_sample_CSV, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for i in range(VALIDATIONLAPS):\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "      for embeddingModel in EMBEDDINGS_MODELS:\n",
    "        current_item += 1\n",
    "        try:\n",
    "          chunk_size = CHUNK_SIZE\n",
    "          if splittingMethod == IngestionMode.token_small:\n",
    "            chunk_size = 128\n",
    "          elif splittingMethod == IngestionMode.token_medium:\n",
    "            chunk_size = 512\n",
    "          elif splittingMethod == IngestionMode.token_large:\n",
    "            chunk_size = 1024\n",
    "            \n",
    "          # Setup\n",
    "          my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "          querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "          # RAG CHAIN\n",
    "          chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "          \n",
    "          # Evaluation\n",
    "          kamervragenEvaluation.evaluate_with_sample_questions(\n",
    "            question_sample_CSV,querier=querier, \n",
    "            toCSV=True, \n",
    "            ingestionMode=splittingMethod, \n",
    "            addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "            addContext=context,\n",
    "            embeddings_model=embeddingModel,\n",
    "            text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "            embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "            database=VECDB_TYPE,\n",
    "            concatFiles=CONCAT_FILES,\n",
    "            )\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          # Write error to file\n",
    "          write_to_error_log(e, f\"splittingMethod={splittingMethod}, context={context}, embeddingModel={embeddingModel}\")\n",
    "          continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"done with {current_item} of {total_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kamervragenEvaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if one single file can be retrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kamervragenEvaluation.test_retrival(\n",
    "  my_folder_path_selected, \n",
    "  ingester, \n",
    "  querier=querier, \n",
    "  toCSV=True,\n",
    "  ingestionMode=IngestionMode.question_answer_per_page, \n",
    "  addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "  addContext=True,\n",
    "  embeddings_model=EMBEDDINGS_MODEL,\n",
    "  text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "  embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "  database=VECDB_TYPE,\n",
    "  ConcatFiles=CONCAT_FILES\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamervragenEvaluation.store_questions_and_answers_CSV(my_folder_path_selected, ingester,concatFiles=CONCAT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamervragenEvaluation.test_retrival_map_grading(\n",
    "  my_folder_path_selected, \n",
    "  ingester, \n",
    "  querier=querier, \n",
    "  toCSV=True,\n",
    "  ingestionMode=IngestionMode.question_answer_per_page, \n",
    "  addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "  addContext=True,\n",
    "  embeddings_model=EMBEDDINGS_MODEL,\n",
    "  text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "  embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "  database=VECDB_TYPE,\n",
    "  concatFiles=CONCAT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
