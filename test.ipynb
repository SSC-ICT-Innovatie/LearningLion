{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imports\n",
    "import os\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from loguru import logger\n",
    "# local imports\n",
    "from ingest.ingester import Ingester\n",
    "from query.querier import Querier\n",
    "from summarize.summarizer import Summarizer\n",
    "import settings\n",
    "import utils as ut\n",
    "from query.querier import EnumMode\n",
    "from ingest.ingester import IngestionMode\n",
    "from datetime import datetime\n",
    "import kamervragenEvaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT= \"\"\"\n",
    "### OBJECTIVE ###\n",
    "Je bent een assistent voor de rijksoverheid. Jouw taak is om vragen te beantwoorden in het Nederlands. Zorg ervoor dat je alleen antwoord geeft op basis van de beschikbare context en dat je daar ook naar verwijst in je antwoord.\n",
    "\n",
    "### AUDIENCE ###\n",
    "De doelgroep van jouw antwoorden zijn ambtenaren. Geef alle relevante informatie uit de context, antwoord in het Nederlands leg in maximaal 100 woorden zoveel mogelijk uit.\n",
    "\n",
    "### GUARDRAILS ###\n",
    "Indien de context onvoldoende informatie bevat om de vraag te beantwoorden, verzin dan geen informatie maar geef aan dat er onvoldoende informatie beschikbaar is.\n",
    "\n",
    "### INSTRUCTIONS ###\n",
    "- Beantwoord de vraag altijd in het Nederlands, zelfs als de context in het Engels is gesteld.\n",
    "- Vermijd het herhalen van de vraag in het antwoord en het herhalen van de instructies. Voer de instructies uit en geef een concreet antwoord op de gestelde vraag.\n",
    "- Geef een stapsgewijze redenering bij het beantwoorden van de vraag en refereer naar specifieke zinnen uit de context die hebben bijgedragen aan het antwoord.\n",
    "- Houd je antwoord nauw verbonden met de context en vermijd het toevoegen van informatie die niet expliciet in de context wordt vermeld.\n",
    "\n",
    "- Voor meer informatie over de context, zeg het bestandsnaam die gevonden is in de source_document. Mits deze beschikbaar is.\n",
    "### QUESTION ### \\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Commented the settings that arent used as parameters in the functions\n",
    "\n",
    "# DOC_DIR = \"./docs\"\n",
    "# CHUNK_DIR = \"./chunks\"\n",
    "# VECDB_DIR = \"./vector_stores\"\n",
    "# EVAL_DIR = \"./evaluate\"\n",
    "# EVAL_APP_HEADER = \"Evaluation\"\n",
    "# EVAL_APP_INFO = \"./info/evaluation_explanation.txt\"\n",
    "# EVAL_FILE_NAME = \"eval.json\"\n",
    "# CHAIN_VERBOSITY = False\n",
    "LLM_TYPE = \"local_llm\"\n",
    "LLM_MODEL_TYPE = \"gemma2\"\n",
    "# API_URL = \"http://127.0.0.1:11434\"\n",
    "AZUREOPENAI_API_VERSION = \"2023-08-01-preview\"\n",
    "EMBEDDINGS_PROVIDER = \"local_embeddings\"\n",
    "EMBEDDINGS_MODEL = \"textgain/allnli-GroNLP-bert-base-dutch-cased\"\n",
    "TEXT_SPLITTER_METHOD = \"NLTKTextSplitter\"\n",
    "# CHAIN_NAME = \"conversationalretrievalchain\"\n",
    "# CHAIN_TYPE = \"stuff\"\n",
    "# SEARCH_TYPE = \"similarity\"\n",
    "# SCORE_THRESHOLD = 0.5\n",
    "VECDB_TYPE = \"chromadb\"\n",
    "CHUNK_SIZE = 1024\n",
    "# CHUNK_K = 4\n",
    "CHUNK_OVERLAP = 256\n",
    "# RETRIEVAL_METHOD = \"regular\"\n",
    "\n",
    "\n",
    "folderSelected = \"kamerVragen\"\n",
    "my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected)\n",
    "\n",
    "CONCAT_FILES = True\n",
    "question_sample_CSV = \"question_sample.csv\"\n",
    "VALIDATIONLAPS = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITTING_METHODS = [IngestionMode.question_answer,IngestionMode.token_small,IngestionMode.token_medium,IngestionMode.token_large]\n",
    "CONTEXT_PRESENT= [True]\n",
    "EMBEDDINGS_MODELS = [\"GroNLP/bert-base-dutch-cased\",\"textgain/allnli-GroNLP-bert-base-dutch-cased\", \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\"dunzhang/stella_en_400M_v5\", \"actualdata/jina-embeddings-v3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "querier = None\n",
    "ingester = None\n",
    "\n",
    "def init(LLM_TYPE=LLM_TYPE, LLM_MODEL_TYPE=LLM_MODEL_TYPE, EMBEDDINGS_MODEL=EMBEDDINGS_MODEL, EMBEDDINGS_PROVIDER=EMBEDDINGS_PROVIDER, AZUREOPENAI_API_VERSION=AZUREOPENAI_API_VERSION, TEXT_SPLITTER_METHOD=TEXT_SPLITTER_METHOD, CHUNK_SIZE=CHUNK_SIZE, CHUNK_OVERLAP=CHUNK_OVERLAP, VECDB_TYPE=VECDB_TYPE, vectordb_folder= my_vectordb_folder_path_selected, content_folder=my_folder_path_selected):\n",
    "  # Init\n",
    "  querier = Querier(\n",
    "    llm_type=LLM_TYPE, \n",
    "    llm_model_type=LLM_MODEL_TYPE, \n",
    "    embeddings_model=EMBEDDINGS_MODEL, \n",
    "    embeddings_provider=EMBEDDINGS_PROVIDER, \n",
    "    azureopenai_api_version=AZUREOPENAI_API_VERSION\n",
    "    )\n",
    "\n",
    "  ingester = Ingester(\n",
    "    collection_name=folderSelected, \n",
    "    content_folder=content_folder, \n",
    "    vectordb_folder=vectordb_folder,\n",
    "    embeddings_model=EMBEDDINGS_MODEL,\n",
    "    text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    vecdb_type=VECDB_TYPE\n",
    "    )\n",
    "  return [querier,ingester]\n",
    "  \n",
    "# querier,ingester = init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(mode=IngestionMode.question_answer_per_page, forceRebuild=True, addedMetaDataURLCSV=\"docs/metadata.csv\", addContext=True):\n",
    "  \"\"\"Ingest the documents in the folder\"\"\"\n",
    "  ingester.ingest(mode=mode, forceRebuild=forceRebuild, addedMetaDataURLCSV=addedMetaDataURLCSV, addContext=addContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain(vectorDBPATH = my_vectordb_folder_path_selected):\n",
    "  \"\"\"Build the RAG Chain\"\"\"\n",
    "  querier.make_chain(folderSelected, vectorDBPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample questions\n",
    "\n",
    "If no sample is provided the tests will not run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "querier,ingester = init(EMBEDDINGS_MODEL=EMBEDDINGS_MODEL, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "kamervragenEvaluation.create_evaluation_sample_questions(my_folder_path_selected,ingester=ingester, destinationCSV=question_sample_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ingest and evaluate\n",
    "\n",
    "Ingest the questions and evaluate the performance of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markheijnekamp/Documents/GitHub/LearningLion-kamervragen/utils.py:121: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "No sentence-transformers model found with name GroNLP/bert-base-dutch-cased. Creating a new one with mean pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2024-10-07 13:17:13.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mgetEmbeddings\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mLoaded local embeddings: GroNLP/bert-base-dutch-cased\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:13.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_class.llm_class\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mUse Local LLM\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:13.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_class.llm_class\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRetrieving gemma2\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:13.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_class.llm_class\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mUsing local api url http://127.0.0.1:11434\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:13.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_class.llm_class\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mRetrieved gemma2\u001b[0m\n",
      "No sentence-transformers model found with name GroNLP/bert-base-dutch-cased. Creating a new one with mean pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2024-10-07 13:17:14.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mgetEmbeddings\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mLoaded local embeddings: GroNLP/bert-base-dutch-cased\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mSkipping ingestion of file .DS_Store because it has extension tore\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mVector store to be created for folder ./docs/kamerVragen\u001b[0m\n",
      "/Users/markheijnekamp/Documents/GitHub/LearningLion-kamervragen/utils.py:61: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n",
      "\u001b[32m2024-10-07 13:17:14.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mFiles are added, so vector store for ./docs/kamerVragen needs to be updated\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.file_parser\u001b[0m:\u001b[36mparse_pdf\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mExtracting metadata\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.file_parser\u001b[0m:\u001b[36mparse_pdf\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mNone\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.file_parser\u001b[0m:\u001b[36mparse_pdf\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mExtracting pages\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mData found for id 0b396175-c27f-4270-952a-d372d0403d13:\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mclean_text\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mCleaning text of each page\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:14.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 1\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:15.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 2\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:15.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 3\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:15.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 4\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:15.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 5\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:15.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mExtracted 20 chunks from 0b396175-c27f-4270-952a-d372d0403d13.pdf\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:15.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m250\u001b[0m - \u001b[1mFile numer 1 of 30\u001b[0m\n",
      "\u001b[32m2024-10-07 13:17:15.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m251\u001b[0m - \u001b[1mProgrssion: 3.3333333333333335%\u001b[0m\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "\u001b[32m2024-10-07 13:18:37.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.file_parser\u001b[0m:\u001b[36mparse_pdf\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mExtracting metadata\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.file_parser\u001b[0m:\u001b[36mparse_pdf\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mNone\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.file_parser\u001b[0m:\u001b[36mparse_pdf\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mExtracting pages\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mData found for id 0cc7f71d-0772-482e-b783-77dadeaf8055:\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mclean_text\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mCleaning text of each page\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 1\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 2\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingest_utils\u001b[0m:\u001b[36mtext_to_docs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSplitting page 3\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mExtracted 10 chunks from 0cc7f71d-0772-482e-b783-77dadeaf8055.pdf\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m250\u001b[0m - \u001b[1mFile numer 2 of 30\u001b[0m\n",
      "\u001b[32m2024-10-07 13:18:37.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mingest.ingester\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m251\u001b[0m - \u001b[1mProgrssion: 6.666666666666667%\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m querier,ingester \u001b[38;5;241m=\u001b[39m init(EMBEDDINGS_MODEL\u001b[38;5;241m=\u001b[39membeddingModel, vectordb_folder\u001b[38;5;241m=\u001b[39mmy_vectordb_folder_path_selected)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Ingestion\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplittingMethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddContext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddedMetaDataURLCSV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocs/metadata.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# RAG CHAIN\u001b[39;00m\n\u001b[1;32m     26\u001b[0m chain(vectorDBPATH\u001b[38;5;241m=\u001b[39mmy_vectordb_folder_path_selected)\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mingest\u001b[0;34m(mode, forceRebuild, addedMetaDataURLCSV, addContext)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mingest\u001b[39m(mode\u001b[38;5;241m=\u001b[39mIngestionMode\u001b[38;5;241m.\u001b[39mquestion_answer_per_page, forceRebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, addedMetaDataURLCSV\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs/metadata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, addContext\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Ingest the documents in the folder\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m   \u001b[43mingester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforceRebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforceRebuild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddedMetaDataURLCSV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddedMetaDataURLCSV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddContext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddContext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/LearningLion-kamervragen/ingest/ingester.py:266\u001b[0m, in \u001b[0;36mIngester.ingest\u001b[0;34m(self, mode, forceRebuild, addedMetaDataURLCSV, addContext)\u001b[0m\n\u001b[1;32m    264\u001b[0m         documents \u001b[38;5;241m=\u001b[39m documents[:\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m addContext:\n\u001b[0;32m--> 266\u001b[0m     introduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mget_context(documents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# Ensure you are updating documents[0], which was used previously\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     documents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintroduction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocuments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:635\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:495\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from error import write_to_error_log\n",
    "\n",
    "\n",
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for embeddingModel in EMBEDDINGS_MODELS:\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "      for i in range(VALIDATIONLAPS):\n",
    "        current_item += 1\n",
    "        try:\n",
    "          chunk_size = CHUNK_SIZE\n",
    "          if splittingMethod == IngestionMode.token_small:\n",
    "            chunk_size = 128\n",
    "          elif splittingMethod == IngestionMode.token_medium:\n",
    "            chunk_size = 512\n",
    "          elif splittingMethod == IngestionMode.token_large:\n",
    "            chunk_size = 1024\n",
    "            \n",
    "          # Setup\n",
    "          my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "          querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "          # Ingestion\n",
    "          ingest(mode=splittingMethod, addContext=context, addedMetaDataURLCSV=\"docs/metadata.csv\")\n",
    "          # RAG CHAIN\n",
    "          chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "          \n",
    "          # Evaluation\n",
    "          kamervragenEvaluation.evaluate_with_sample_questions(\n",
    "            question_sample_CSV,querier=querier, \n",
    "            toCSV=True, \n",
    "            ingestionMode=splittingMethod, \n",
    "            addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "            addContext=context,\n",
    "            embeddings_model=embeddingModel,\n",
    "            text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "            embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "            database=VECDB_TYPE,\n",
    "            concatFiles=CONCAT_FILES,\n",
    "            selected_files_folder=my_folder_path_selected\n",
    "            )\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          # Write error to file\n",
    "          write_to_error_log(\"error_log_test.txt\", e, f\"splittingMethod={splittingMethod}, context={context}, embeddingModel={embeddingModel}\")\n",
    "          continue\n",
    "        \n",
    "        \n",
    "        print(f\"done with {current_item} of {total_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and evaluate larger models on the same data\n",
    "The larger models selected are  \"BAAI/bge-multilingual-gemma2\", \"Alibaba-NLP/gte-Qwen2-7B-instruct\",\"Alibaba-NLP/gte-multilingual-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LongTimeEmbeddingsModels = [\"BAAI/bge-multilingual-gemma2\", \"Alibaba-NLP/gte-Qwen2-7B-instruct\",\"Alibaba-NLP/gte-multilingual-base\"]\n",
    "\n",
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for embeddingModel in EMBEDDINGS_MODELS:\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "      for i in range(VALIDATIONLAPS):\n",
    "        current_item += 1\n",
    "        try:\n",
    "          chunk_size = CHUNK_SIZE\n",
    "          if splittingMethod == IngestionMode.token_small:\n",
    "            chunk_size = 128\n",
    "          elif splittingMethod == IngestionMode.token_medium:\n",
    "            chunk_size = 512\n",
    "          elif splittingMethod == IngestionMode.token_large:\n",
    "            chunk_size = 1024\n",
    "            \n",
    "          # Setup\n",
    "          my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "          querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "          # Ingestion\n",
    "          ingest(mode=splittingMethod, addContext=context, addedMetaDataURLCSV=\"docs/metadata.csv\")\n",
    "          # RAG CHAIN\n",
    "          chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "          \n",
    "          # Evaluation\n",
    "          kamervragenEvaluation.evaluate_with_sample_questions(\n",
    "            question_sample_CSV,querier=querier, \n",
    "            toCSV=True, \n",
    "            ingestionMode=splittingMethod, \n",
    "            addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "            addContext=context,\n",
    "            embeddings_model=embeddingModel,\n",
    "            text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "            embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "            database=VECDB_TYPE,\n",
    "            concatFiles=CONCAT_FILES,\n",
    "            selected_files_folder=my_folder_path_selected\n",
    "            )\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          # Write error to file\n",
    "          write_to_error_log(e, f\"splittingMethod={splittingMethod}, context={context}, embeddingModel={embeddingModel}\")\n",
    "          continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"done with {current_item} of {total_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test items\n",
    "\n",
    "This uses the existing database that has already been ingested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for embeddingModel in EMBEDDINGS_MODELS:\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "        for i in range(VALIDATIONLAPS):\n",
    "          current_item += 1\n",
    "          try:\n",
    "            chunk_size = CHUNK_SIZE\n",
    "            if splittingMethod == IngestionMode.token_small:\n",
    "              chunk_size = 128\n",
    "            elif splittingMethod == IngestionMode.token_medium:\n",
    "              chunk_size = 512\n",
    "            elif splittingMethod == IngestionMode.token_large:\n",
    "              chunk_size = 1024\n",
    "              \n",
    "            # Setup\n",
    "            my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "            querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "            # RAG CHAIN\n",
    "            chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "            \n",
    "            # Evaluation\n",
    "            kamervragenEvaluation.evaluate_with_sample_questions(\n",
    "              question_sample_CSV,querier=querier, \n",
    "              toCSV=True, \n",
    "              ingestionMode=splittingMethod, \n",
    "              addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "              addContext=context,\n",
    "              embeddings_model=embeddingModel,\n",
    "              text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "              embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "              database=VECDB_TYPE,\n",
    "              concatFiles=CONCAT_FILES,\n",
    "              selected_files_folder=my_folder_path_selected\n",
    "              )\n",
    "          except Exception as e:\n",
    "            print(e)\n",
    "            # Write error to file\n",
    "            write_to_error_log(e, f\"splittingMethod={splittingMethod}, context={context}, embeddingModel={embeddingModel}\")\n",
    "            continue\n",
    "          \n",
    "          \n",
    "          \n",
    "          print(f\"done with {current_item} of {total_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for embeddingModel in EMBEDDINGS_MODELS:\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "        for i in range(VALIDATIONLAPS):\n",
    "          current_item += 1\n",
    "          try:\n",
    "            chunk_size = CHUNK_SIZE\n",
    "            if splittingMethod == IngestionMode.token_small:\n",
    "              chunk_size = 128\n",
    "            elif splittingMethod == IngestionMode.token_medium:\n",
    "              chunk_size = 512\n",
    "            elif splittingMethod == IngestionMode.token_large:\n",
    "              chunk_size = 1024\n",
    "              \n",
    "            # Setup\n",
    "            my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "            querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "            # RAG CHAIN\n",
    "            chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "            \n",
    "            # Evaluation\n",
    "            kamervragenEvaluation.evaluate_with_sample_questions(\n",
    "              question_sample_CSV,querier=querier, \n",
    "              toCSV=True, \n",
    "              ingestionMode=splittingMethod, \n",
    "              addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "              addContext=context,\n",
    "              embeddings_model=embeddingModel,\n",
    "              text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "              embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "              database=VECDB_TYPE,\n",
    "              concatFiles=CONCAT_FILES,\n",
    "              selected_files_folder=my_folder_path_selected\n",
    "              )\n",
    "          except Exception as e:\n",
    "            print(e)\n",
    "            # Write error to file\n",
    "            write_to_error_log(e, f\"splittingMethod={splittingMethod}, context={context}, embeddingModel={embeddingModel}\")\n",
    "            continue\n",
    "          \n",
    "          \n",
    "          \n",
    "          print(f\"done with {current_item} of {total_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "splittingMethod = IngestionMode.token_small\n",
    "embeddingModel = \"textgain/allnli-GroNLP-bert-base-dutch-cased\"\n",
    "context = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "chain(vectorDBPATH=my_vectordb_folder_path_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querier.get_documents_with_scores(\"\"\"Vraag 2\n",
    "Kunt u in kaart brengen hoeveel en mogelijk welke bedrijven nieuwe\n",
    "investeringen doen in het buitenland in plaats van Nederland, of dit\n",
    "overwegen? Wat zijn hiervoor de voornaamste drijfveren?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
