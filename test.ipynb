{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imports\n",
    "import os\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from loguru import logger\n",
    "# local imports\n",
    "from ingest.ingester import Ingester\n",
    "from query.querier import Querier\n",
    "from summarize.summarizer import Summarizer\n",
    "import settings\n",
    "import utils as ut\n",
    "from query.querier import EnumMode\n",
    "from ingest.ingester import IngestionMode\n",
    "\n",
    "import kamervragenEvaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT= \"\"\"\n",
    "### OBJECTIVE ###\n",
    "Je bent een assistent voor de rijksoverheid. Jouw taak is om vragen te beantwoorden in het Nederlands. Zorg ervoor dat je alleen antwoord geeft op basis van de beschikbare context en dat je daar ook naar verwijst in je antwoord.\n",
    "\n",
    "### AUDIENCE ###\n",
    "De doelgroep van jouw antwoorden zijn ambtenaren. Geef alle relevante informatie uit de context, antwoord in het Nederlands leg in maximaal 100 woorden zoveel mogelijk uit.\n",
    "\n",
    "### GUARDRAILS ###\n",
    "Indien de context onvoldoende informatie bevat om de vraag te beantwoorden, verzin dan geen informatie maar geef aan dat er onvoldoende informatie beschikbaar is.\n",
    "\n",
    "### INSTRUCTIONS ###\n",
    "- Beantwoord de vraag altijd in het Nederlands, zelfs als de context in het Engels is gesteld.\n",
    "- Vermijd het herhalen van de vraag in het antwoord en het herhalen van de instructies. Voer de instructies uit en geef een concreet antwoord op de gestelde vraag.\n",
    "- Geef een stapsgewijze redenering bij het beantwoorden van de vraag en refereer naar specifieke zinnen uit de context die hebben bijgedragen aan het antwoord.\n",
    "- Houd je antwoord nauw verbonden met de context en vermijd het toevoegen van informatie die niet expliciet in de context wordt vermeld.\n",
    "\n",
    "- Voor meer informatie over de context, zeg het bestandsnaam die gevonden is in de source_document. Mits deze beschikbaar is.\n",
    "### QUESTION ### \\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Commented the settings that arent used as parameters in the functions\n",
    "\n",
    "# DOC_DIR = \"./docs\"\n",
    "# CHUNK_DIR = \"./chunks\"\n",
    "# VECDB_DIR = \"./vector_stores\"\n",
    "# EVAL_DIR = \"./evaluate\"\n",
    "# EVAL_APP_HEADER = \"Evaluation\"\n",
    "# EVAL_APP_INFO = \"./info/evaluation_explanation.txt\"\n",
    "# EVAL_FILE_NAME = \"eval.json\"\n",
    "# CHAIN_VERBOSITY = False\n",
    "LLM_TYPE = \"local_llm\"\n",
    "LLM_MODEL_TYPE = \"gemma2\"\n",
    "# API_URL = \"http://127.0.0.1:11434\"\n",
    "AZUREOPENAI_API_VERSION = \"2023-08-01-preview\"\n",
    "EMBEDDINGS_PROVIDER = \"local_embeddings\"\n",
    "EMBEDDINGS_MODEL = \"textgain/allnli-GroNLP-bert-base-dutch-cased\"\n",
    "TEXT_SPLITTER_METHOD = \"NLTKTextSplitter\"\n",
    "# CHAIN_NAME = \"conversationalretrievalchain\"\n",
    "# CHAIN_TYPE = \"stuff\"\n",
    "# SEARCH_TYPE = \"similarity\"\n",
    "# SCORE_THRESHOLD = 0.5\n",
    "VECDB_TYPE = \"chromadb\"\n",
    "CHUNK_SIZE = 1024\n",
    "# CHUNK_K = 4\n",
    "CHUNK_OVERLAP = 256\n",
    "# RETRIEVAL_METHOD = \"regular\"\n",
    "\n",
    "\n",
    "folderSelected = \"kamerVragen\"\n",
    "my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected)\n",
    "\n",
    "CONCAT_FILES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITTING_METHODS = [IngestionMode.question_answer,IngestionMode.token_small,IngestionMode.token_medium,IngestionMode.token_large]\n",
    "CONTEXT_PRESENT= [True, False]\n",
    "EMBEDDINGS_MODELS = [\"GroNLP/bert-base-dutch-cased\",\"textgain/allnli-GroNLP-bert-base-dutch-cased\", \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\"dunzhang/stella_en_400M_v5\",\"BAAI/bge-multilingual-gemma2\",\"Alibaba-NLP/gte-Qwen2-7B-instruct\",\"Alibaba-NLP/gte-multilingual-base\", \"actualdata/jina-embeddings-v3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "querier = None\n",
    "ingester = None\n",
    "\n",
    "def init(LLM_TYPE=LLM_TYPE, LLM_MODEL_TYPE=LLM_MODEL_TYPE, EMBEDDINGS_MODEL=EMBEDDINGS_MODEL, EMBEDDINGS_PROVIDER=EMBEDDINGS_PROVIDER, AZUREOPENAI_API_VERSION=AZUREOPENAI_API_VERSION, TEXT_SPLITTER_METHOD=TEXT_SPLITTER_METHOD, CHUNK_SIZE=CHUNK_SIZE, CHUNK_OVERLAP=CHUNK_OVERLAP, VECDB_TYPE=VECDB_TYPE, vectordb_folder= my_vectordb_folder_path_selected, content_folder=my_folder_path_selected):\n",
    "  # Init\n",
    "  querier = Querier(\n",
    "    llm_type=LLM_TYPE, \n",
    "    llm_model_type=LLM_MODEL_TYPE, \n",
    "    embeddings_model=EMBEDDINGS_MODEL, \n",
    "    embeddings_provider=EMBEDDINGS_PROVIDER, \n",
    "    azureopenai_api_version=AZUREOPENAI_API_VERSION\n",
    "    )\n",
    "\n",
    "  ingester = Ingester(\n",
    "    collection_name=folderSelected, \n",
    "    content_folder=content_folder, \n",
    "    vectordb_folder=vectordb_folder,\n",
    "    embeddings_model=EMBEDDINGS_MODEL,\n",
    "    text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    vecdb_type=VECDB_TYPE\n",
    "    )\n",
    "  return [querier,ingester]\n",
    "  \n",
    "# querier,ingester = init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(mode=IngestionMode.question_answer_per_page, forceRebuild=True, addedMetaDataURLCSV=\"docs/metadata.csv\", addContext=True):\n",
    "  ingester.ingest(mode=mode, forceRebuild=forceRebuild, addedMetaDataURLCSV=addedMetaDataURLCSV, addContext=addContext)\n",
    "# ingest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain(vectorDBPATH = my_vectordb_folder_path_selected):\n",
    "  querier.make_chain(folderSelected, vectorDBPATH)\n",
    "# chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# querier.ask_question(\"\"\"\n",
    "#                      Kwamen er 82 treinen stil te staan tijdens hun rit?\n",
    "#                      \"\"\", mode=EnumMode.metadata, system_prompt_override=SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place folder contents in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "File generation"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from chunker import clean_pages\n",
    "# from ingest.file_parser import FileParser\n",
    "# import json \n",
    "\n",
    "# processed = []\n",
    "# file_parser = FileParser()\n",
    "\n",
    "# # Process files\n",
    "# for file in os.listdir(my_folder_path_selected):\n",
    "#   if not file.endswith(\".pdf\"):\n",
    "#     continue\n",
    "#   print(\"start processing file: \", file)\n",
    "#   file_path = os.path.join(my_folder_path_selected, file)\n",
    "#   raw_pages, _ = file_parser.parse_file(file_path)\n",
    "#   cleaned_pages = clean_pages(raw_pages)\n",
    "#   processed.extend(cleaned_pages)\n",
    "\n",
    "# # Write processed pages to json file\n",
    "# print(\"writing processed pages to json file\")\n",
    "# output_file = os.path.join(my_folder_path_selected, \"processed.json\")\n",
    "\n",
    "# with open(output_file, \"w\") as f:\n",
    "#   json.dump(processed, f)\n",
    "\n",
    "# print(\"done\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATIONLAPS = 10\n",
    "current_item = 0\n",
    "total_items = VALIDATIONLAPS * len(SPLITTING_METHODS) * len(CONTEXT_PRESENT) * len(EMBEDDINGS_MODELS)\n",
    "for time in range(VALIDATIONLAPS):\n",
    "  for splittingMethod in SPLITTING_METHODS:\n",
    "    for context in CONTEXT_PRESENT:\n",
    "      for embeddingModel in EMBEDDINGS_MODELS:\n",
    "        try:\n",
    "          chunk_size = CHUNK_SIZE\n",
    "          if splittingMethod == IngestionMode.token_small:\n",
    "            chunk_size = 128\n",
    "          elif splittingMethod == IngestionMode.token_medium:\n",
    "            chunk_size = 512\n",
    "          elif splittingMethod == IngestionMode.token_large:\n",
    "            chunk_size = 1024\n",
    "            \n",
    "          # Setup\n",
    "          my_folder_path_selected, my_vectordb_folder_path_selected = ut.create_vectordb_name(folderSelected, chunk_size=chunk_size, chunk_overlap=0, splitting_method=splittingMethod, embeddings_model=embeddingModel, added_context=context)\n",
    "          querier,ingester = init(EMBEDDINGS_MODEL=embeddingModel, vectordb_folder=my_vectordb_folder_path_selected)\n",
    "          # Ingestion\n",
    "          ingest(mode=splittingMethod, addContext=context, addedMetaDataURLCSV=\"docs/metadata.csv\")\n",
    "          # RAG CHAIN\n",
    "          chain(vectorDBPATH=my_vectordb_folder_path_selected)\n",
    "          \n",
    "          # Evaluation\n",
    "          kamervragenEvaluation.test_retrival(\n",
    "              my_folder_path_selected, \n",
    "              ingester, \n",
    "              querier=querier, \n",
    "              toCSV=True,\n",
    "              ingestionMode=splittingMethod, \n",
    "              addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "              addContext=context,\n",
    "              embeddings_model=embeddingModel,\n",
    "              text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "              embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "              database=VECDB_TYPE,\n",
    "              ConcatFiles=CONCAT_FILES,\n",
    "          )\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          # Write error to file\n",
    "          with open(\"error.txt\", \"a\") as f:\n",
    "            f.write(f\"Error: {e} \\n\")\n",
    "          continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"done with {current_item} of {total_items}\")\n",
    "  print(f\"Done with iteration {time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kamervragenEvaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if one single file can be retrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kamervragenEvaluation.test_retrival(\n",
    "  my_folder_path_selected, \n",
    "  ingester, \n",
    "  querier=querier, \n",
    "  toCSV=True,\n",
    "  ingestionMode=IngestionMode.question_answer_per_page, \n",
    "  addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "  addContext=True,\n",
    "  embeddings_model=EMBEDDINGS_MODEL,\n",
    "  text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "  embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "  database=VECDB_TYPE,\n",
    "  ConcatFiles=CONCAT_FILES\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamervragenEvaluation.store_questions_and_answers_CSV(my_folder_path_selected, ingester,concatFiles=CONCAT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamervragenEvaluation.test_retrival_map_grading(\n",
    "  my_folder_path_selected, \n",
    "  ingester, \n",
    "  querier=querier, \n",
    "  toCSV=True,\n",
    "  ingestionMode=IngestionMode.question_answer_per_page, \n",
    "  addedMetaDataURLCSV=\"docs/metadata.csv\", \n",
    "  addContext=True,\n",
    "  embeddings_model=EMBEDDINGS_MODEL,\n",
    "  text_splitter_method=TEXT_SPLITTER_METHOD,\n",
    "  embeddings_provider=EMBEDDINGS_PROVIDER,\n",
    "  database=VECDB_TYPE,\n",
    "  concatFiles=CONCAT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
